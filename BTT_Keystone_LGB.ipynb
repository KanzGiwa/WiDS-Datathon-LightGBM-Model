{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "37197108c7a44380ab33e070cee9b3ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb568ec77d0845df9d3eb862c3998a80",
              "IPY_MODEL_6b6a170c74334f6a9e4f226bb36d10f6",
              "IPY_MODEL_bbb37c5aa65d4d90b3970dca314b95a0"
            ],
            "layout": "IPY_MODEL_c552f205c3ed492dbdf14897a976794e"
          }
        },
        "bb568ec77d0845df9d3eb862c3998a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21e4e84fa2604797a87d5d707bd15101",
            "placeholder": "​",
            "style": "IPY_MODEL_a820001a3ec7435395bf7c6c3d6f007c",
            "value": "Best trial: 49. Best value: 0.0600946: 100%"
          }
        },
        "6b6a170c74334f6a9e4f226bb36d10f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18675621829b4bd99dcfb36bf4a408e5",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_47699ab28f0544cbbc21f6e3df6f0c63",
            "value": 50
          }
        },
        "bbb37c5aa65d4d90b3970dca314b95a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae7610b71e564724ba1d499ce9cfbd29",
            "placeholder": "​",
            "style": "IPY_MODEL_9144564693114f03b6d074615d5a6b16",
            "value": " 50/50 [00:08&lt;00:00,  4.54it/s]"
          }
        },
        "c552f205c3ed492dbdf14897a976794e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21e4e84fa2604797a87d5d707bd15101": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a820001a3ec7435395bf7c6c3d6f007c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18675621829b4bd99dcfb36bf4a408e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47699ab28f0544cbbc21f6e3df6f0c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae7610b71e564724ba1d499ce9cfbd29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9144564693114f03b6d074615d5a6b16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "KHljTb_JZ_Wp"
      },
      "outputs": [],
      "source": [
        "# ==============================================================================\n",
        "# WILDFIRE EVACUATION THREAT PREDICTION -- LightGBM Survival Model\n",
        "# Goal: Hybrid Score >= 0.99 (0.3 * C-index + 0.7 * (1 - Weighted Brier Score))\n",
        "# ==============================================================================\n",
        "\n",
        "# -- STEP 0: Install dependencies ----------------------------------------------\n",
        "# !pip install lightgbm scikit-survival optuna shap lifelines --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import lightgbm as lgb\n",
        "import optuna\n",
        "import shap\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 1: Load Data\n",
        "# ==============================================================================\n",
        "\n",
        "train = pd.read_csv('train.csv')\n",
        "test  = pd.read_csv('test.csv')\n",
        "sub   = pd.read_csv('sample_submission.csv')\n",
        "\n",
        "print(f\"Train: {train.shape} | Test: {test.shape}\")\n",
        "print(f\"Event rate (fires that hit): {train['event'].mean():.1%}\")\n",
        "print(f\"Time-to-hit range: {train['time_to_hit_hours'].min():.1f}h to {train['time_to_hit_hours'].max():.1f}h\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJUm3eDom0BP",
        "outputId": "29eec4d2-c559-444b-fb40-fd90110ceb8d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: (221, 37) | Test: (95, 35)\n",
            "Event rate (fires that hit): 31.2%\n",
            "Time-to-hit range: 0.0h to 67.0h\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 2: Feature Engineering\n",
        "# ==============================================================================\n",
        "\n",
        "def engineer_features(df):\n",
        "    df = df.copy()\n",
        "\n",
        "    # Proximity danger score -- close + fast growing = biggest threat\n",
        "    df['danger_score'] = df['area_growth_rate_ha_per_h'] / (df['dist_min_ci_0_5h'] + 1)\n",
        "\n",
        "    # Naive time-to-close-the-gap estimate (distance / closing speed)\n",
        "    # Gives the model a direct survival-time signal\n",
        "    safe_closing = df['closing_speed_m_per_h'].clip(lower=1)\n",
        "    df['eta_hours_naive'] = (df['dist_min_ci_0_5h'] / safe_closing).clip(upper=72)\n",
        "\n",
        "    # Binary risk flags for clean split boundaries\n",
        "    df['is_fast_grower']   = (df['area_growth_rate_ha_per_h'] > df['area_growth_rate_ha_per_h'].quantile(0.75)).astype(int)\n",
        "    df['is_close_to_evac'] = (df['dist_min_ci_0_5h'] < df['dist_min_ci_0_5h'].quantile(0.25)).astype(int)\n",
        "    df['is_low_res']       = df['low_temporal_resolution_0_5h'].astype(int)\n",
        "\n",
        "    # Spread geometry\n",
        "    df['is_advancing']   = (df['along_track_speed'] > 0).astype(int)\n",
        "    df['aligned_threat'] = df['alignment_abs'] * df['closing_speed_abs_m_per_h']\n",
        "\n",
        "    # Log-transform skewed features\n",
        "    df['log_dist_min']      = np.log1p(df['dist_min_ci_0_5h'])\n",
        "    df['log_closing_speed'] = np.log1p(df['closing_speed_abs_m_per_h'])\n",
        "    df['log_eta']           = np.log1p(df['eta_hours_naive'])\n",
        "\n",
        "    # Negative acceleration = fire accelerating toward evac zone\n",
        "    df['is_accelerating_toward'] = (df['dist_accel_m_per_h2'] < 0).astype(int)\n",
        "\n",
        "    # Interaction: large fire heading toward a zone is a compounding risk\n",
        "    df['area_x_alignment'] = df['log1p_area_first'] * df['alignment_abs']\n",
        "\n",
        "    # Temporal context: afternoon ignitions and fire season months are more dangerous\n",
        "    df['is_peak_hour']  = ((df['event_start_hour'] >= 12) & (df['event_start_hour'] <= 18)).astype(int)\n",
        "    df['is_peak_month'] = df['event_start_month'].isin([6, 7, 8, 9]).astype(int)\n",
        "\n",
        "    return df\n",
        "\n",
        "train = engineer_features(train)\n",
        "test  = engineer_features(test)\n",
        "\n",
        "NON_FEATURES = ['event_id', 'time_to_hit_hours', 'event']\n",
        "FEATURE_COLS = [c for c in train.columns if c not in NON_FEATURES]\n",
        "print(f\"\\nTotal features after engineering: {len(FEATURE_COLS)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogJS0w5tftS_",
        "outputId": "45ce8ce2-5c07-4ed7-e38a-539d23591c25"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total features after engineering: 48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 3: Build Binary Targets for Each Horizon\n",
        "# ==============================================================================\n",
        "# For each horizon H:\n",
        "#   POSITIVE:  event=1 AND time_to_hit <= H  (confirmed hit before horizon)\n",
        "#   NEGATIVE:  time_to_hit > H               (fire survived past horizon)\n",
        "#   EXCLUDED:  event=0 AND time_to_hit <= H  (censored before horizon -- truth unknown)\n",
        "\n",
        "HORIZONS = [12, 24, 48, 72]\n",
        "\n",
        "def make_binary_targets(df):\n",
        "    masks = {}\n",
        "    for H in HORIZONS:\n",
        "        hit     = (df['event'] == 1) & (df['time_to_hit_hours'] <= H)\n",
        "        no_hit  = df['time_to_hit_hours'] > H\n",
        "        include = hit | no_hit\n",
        "        df[f'hit_{H}h'] = hit.astype(int)\n",
        "        masks[f'mask_{H}h'] = include\n",
        "    return df, masks\n",
        "\n",
        "train, horizon_masks = make_binary_targets(train)\n",
        "\n",
        "for H in HORIZONS:\n",
        "    mask     = horizon_masks[f'mask_{H}h']\n",
        "    hit_rate = train.loc[mask, f'hit_{H}h'].mean()\n",
        "    print(f\"Horizon {H:2d}h -> usable samples: {mask.sum():3d} | hit rate: {hit_rate:.1%}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAxLrErmlkNi",
        "outputId": "04f1ad0f-6426-4aec-ea70-0dffffe85076"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Horizon 12h -> usable samples: 215 | hit rate: 22.8%\n",
            "Horizon 24h -> usable samples: 196 | hit rate: 32.1%\n",
            "Horizon 48h -> usable samples: 166 | hit rate: 39.8%\n",
            "Horizon 72h -> usable samples:  69 | hit rate: 100.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 4: Optuna Hyperparameter Tuning\n",
        "# ==============================================================================\n",
        "# Tune on the 48h horizon (40% weight in scoring) and reuse params for all horizons.\n",
        "\n",
        "mask_48 = horizon_masks['mask_48h']\n",
        "X_48    = train.loc[mask_48, FEATURE_COLS].reset_index(drop=True)\n",
        "y_48    = train.loc[mask_48, 'hit_48h'].reset_index(drop=True)\n",
        "\n",
        "def lgb_cv_score(trial):\n",
        "    params = {\n",
        "        'objective':         'binary',\n",
        "        'metric':            'binary_logloss',\n",
        "        'verbosity':         -1,\n",
        "        'n_jobs':            -1,\n",
        "        'seed':              SEED,\n",
        "        'num_leaves':        trial.suggest_int('num_leaves', 8, 64),\n",
        "        'learning_rate':     trial.suggest_float('learning_rate', 0.01, 0.15, log=True),\n",
        "        'max_depth':         trial.suggest_int('max_depth', 3, 8),\n",
        "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 40),\n",
        "        'subsample':         trial.suggest_float('subsample', 0.5, 1.0),\n",
        "        'colsample_bytree':  trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
        "        'reg_alpha':         trial.suggest_float('reg_alpha', 1e-4, 5.0, log=True),\n",
        "        'reg_lambda':        trial.suggest_float('reg_lambda', 1e-4, 5.0, log=True),\n",
        "        'n_estimators':      trial.suggest_int('n_estimators', 100, 600),\n",
        "    }\n",
        "    skf    = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
        "    scores = []\n",
        "    for tr_idx, va_idx in skf.split(X_48, y_48):\n",
        "        model       = lgb.LGBMClassifier(**params)\n",
        "        val_classes = np.unique(y_48.iloc[va_idx])\n",
        "        if len(val_classes) < 2:\n",
        "            model.fit(X_48.iloc[tr_idx], y_48.iloc[tr_idx],\n",
        "                      callbacks=[lgb.log_evaluation(-1)])\n",
        "            scores.append(0.0)\n",
        "        else:\n",
        "            model.fit(X_48.iloc[tr_idx], y_48.iloc[tr_idx],\n",
        "                      eval_set=[(X_48.iloc[va_idx], y_48.iloc[va_idx])],\n",
        "                      callbacks=[lgb.early_stopping(30, verbose=False),\n",
        "                                 lgb.log_evaluation(-1)])\n",
        "            preds = model.predict_proba(X_48.iloc[va_idx])[:, 1]\n",
        "            scores.append(log_loss(y_48.iloc[va_idx], preds))\n",
        "    return np.mean(scores)\n",
        "\n",
        "print(\"\\nRunning Optuna hyperparameter search (50 trials)...\")\n",
        "study = optuna.create_study(direction='minimize',\n",
        "                            sampler=optuna.samplers.TPESampler(seed=SEED))\n",
        "study.optimize(lgb_cv_score, n_trials=50, show_progress_bar=True)\n",
        "\n",
        "BEST_PARAMS = study.best_params\n",
        "BEST_PARAMS.update({'objective': 'binary', 'metric': 'binary_logloss',\n",
        "                    'verbosity': -1, 'n_jobs': -1, 'seed': SEED})\n",
        "print(f\"\\nBest params: {BEST_PARAMS}\")\n",
        "print(f\"Best CV log-loss: {study.best_value:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "37197108c7a44380ab33e070cee9b3ca",
            "bb568ec77d0845df9d3eb862c3998a80",
            "6b6a170c74334f6a9e4f226bb36d10f6",
            "bbb37c5aa65d4d90b3970dca314b95a0",
            "c552f205c3ed492dbdf14897a976794e",
            "21e4e84fa2604797a87d5d707bd15101",
            "a820001a3ec7435395bf7c6c3d6f007c",
            "18675621829b4bd99dcfb36bf4a408e5",
            "47699ab28f0544cbbc21f6e3df6f0c63",
            "ae7610b71e564724ba1d499ce9cfbd29",
            "9144564693114f03b6d074615d5a6b16"
          ]
        },
        "id": "E90i9JixlkR5",
        "outputId": "5d482811-8a65-4ec2-b2c4-f1cad6959e3e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Optuna hyperparameter search (50 trials)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "37197108c7a44380ab33e070cee9b3ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best params: {'num_leaves': 26, 'learning_rate': 0.07347677222383225, 'max_depth': 7, 'min_child_samples': 30, 'subsample': 0.8764598226325977, 'colsample_bytree': 0.5934558555856326, 'reg_alpha': 0.001034527831103876, 'reg_lambda': 0.0029559118884026404, 'n_estimators': 319, 'objective': 'binary', 'metric': 'binary_logloss', 'verbosity': -1, 'n_jobs': -1, 'seed': 42}\n",
            "Best CV log-loss: 0.0601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 5: Train One LightGBM per Horizon with Cross-Validation OOF Predictions\n",
        "# ==============================================================================\n",
        "# OOF predictions are stored as {event_id: prob} dicts to avoid pandas index\n",
        "# alignment bugs -- a common silent failure when mixing boolean masks + numpy arrays.\n",
        "\n",
        "N_FOLDS     = 5\n",
        "test_preds  = pd.DataFrame({'event_id': test['event_id']})\n",
        "X_test      = test[FEATURE_COLS]\n",
        "oof_records = {H: {} for H in HORIZONS}\n",
        "\n",
        "for H in HORIZONS:\n",
        "    col  = f'hit_{H}h'\n",
        "    mask = horizon_masks[f'mask_{H}h']\n",
        "\n",
        "    # Reset index so positional iloc and numpy arrays stay aligned\n",
        "    X_h   = train.loc[mask, FEATURE_COLS].reset_index(drop=True)\n",
        "    y_h   = train.loc[mask, col].reset_index(drop=True)\n",
        "    ids_h = train.loc[mask, 'event_id'].reset_index(drop=True)\n",
        "\n",
        "    skf             = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
        "    oof             = np.zeros(len(X_h))\n",
        "    test_fold_preds = np.zeros(len(X_test))\n",
        "\n",
        "    print(f\"\\n-- Horizon {H}h -- ({mask.sum()} samples, {y_h.mean():.1%} hit rate)\")\n",
        "\n",
        "    for fold, (tr_idx, va_idx) in enumerate(skf.split(X_h, y_h)):\n",
        "        model       = lgb.LGBMClassifier(**BEST_PARAMS)\n",
        "        val_classes = np.unique(y_h.iloc[va_idx])\n",
        "\n",
        "        if len(val_classes) < 2:\n",
        "            # Single-class val fold (common at 72h with 100% hit rate).\n",
        "            # binary_logloss eval would crash, so train without eval_set.\n",
        "            model.fit(X_h.iloc[tr_idx], y_h.iloc[tr_idx],\n",
        "                      callbacks=[lgb.log_evaluation(-1)])\n",
        "            print(f\"  Fold {fold+1}: skipped early stopping (only class {val_classes} in val)\")\n",
        "        else:\n",
        "            model.fit(X_h.iloc[tr_idx], y_h.iloc[tr_idx],\n",
        "                      eval_set=[(X_h.iloc[va_idx], y_h.iloc[va_idx])],\n",
        "                      callbacks=[lgb.early_stopping(50, verbose=False),\n",
        "                                 lgb.log_evaluation(-1)])\n",
        "            fold_preds = model.predict_proba(X_h.iloc[va_idx])[:, 1]\n",
        "            print(f\"  Fold {fold+1}: log-loss = {log_loss(y_h.iloc[va_idx], fold_preds):.4f}\")\n",
        "\n",
        "        oof[va_idx]      = model.predict_proba(X_h.iloc[va_idx])[:, 1]\n",
        "        test_fold_preds += model.predict_proba(X_test)[:, 1] / N_FOLDS\n",
        "\n",
        "    for i, eid in enumerate(ids_h):\n",
        "        oof_records[H][eid] = oof[i]\n",
        "\n",
        "    test_preds[f'prob_{H}h'] = test_fold_preds\n",
        "\n",
        "# Reconstruct oof_preds via safe event_id mapping\n",
        "oof_preds = pd.DataFrame({'event_id': train['event_id']})\n",
        "for H in HORIZONS:\n",
        "    oof_preds[f'prob_{H}h'] = oof_preds['event_id'].map(oof_records[H])\n",
        "\n",
        "print(\"\\nAll horizons trained!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjPjAQdSlkU4",
        "outputId": "64272913-162a-4957-ab25-68c33a250053"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "-- Horizon 12h -- (215 samples, 22.8% hit rate)\n",
            "  Fold 1: log-loss = 0.2399\n",
            "  Fold 2: log-loss = 0.1456\n",
            "  Fold 3: log-loss = 0.0556\n",
            "  Fold 4: log-loss = 0.1355\n",
            "  Fold 5: log-loss = 0.2483\n",
            "\n",
            "-- Horizon 24h -- (196 samples, 32.1% hit rate)\n",
            "  Fold 1: log-loss = 0.0204\n",
            "  Fold 2: log-loss = 0.0984\n",
            "  Fold 3: log-loss = 0.0857\n",
            "  Fold 4: log-loss = 0.1050\n",
            "  Fold 5: log-loss = 0.1626\n",
            "\n",
            "-- Horizon 48h -- (166 samples, 39.8% hit rate)\n",
            "  Fold 1: log-loss = 0.0560\n",
            "  Fold 2: log-loss = 0.1478\n",
            "  Fold 3: log-loss = 0.0209\n",
            "  Fold 4: log-loss = 0.0754\n",
            "  Fold 5: log-loss = 0.0003\n",
            "\n",
            "-- Horizon 72h -- (69 samples, 100.0% hit rate)\n",
            "  Fold 1: skipped early stopping (only class [1] in val)\n",
            "  Fold 2: skipped early stopping (only class [1] in val)\n",
            "  Fold 3: skipped early stopping (only class [1] in val)\n",
            "  Fold 4: skipped early stopping (only class [1] in val)\n",
            "  Fold 5: skipped early stopping (only class [1] in val)\n",
            "\n",
            "All horizons trained!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 6: Enforce Monotonicity\n",
        "# ==============================================================================\n",
        "\n",
        "def enforce_monotonicity(df):\n",
        "    df = df.copy()\n",
        "    df['prob_24h'] = df[['prob_12h', 'prob_24h']].max(axis=1)\n",
        "    df['prob_48h'] = df[['prob_24h', 'prob_48h']].max(axis=1)\n",
        "    df['prob_72h'] = df[['prob_48h', 'prob_72h']].max(axis=1)\n",
        "    return df\n",
        "\n",
        "test_preds = enforce_monotonicity(test_preds)\n",
        "\n",
        "prob_cols      = [f'prob_{H}h' for H in HORIZONS]\n",
        "has_any_pred   = oof_preds[prob_cols].notna().any(axis=1)\n",
        "oof_preds_eval = enforce_monotonicity(oof_preds[has_any_pred].copy())\n",
        "print(f\"OOF rows available for evaluation: {has_any_pred.sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DymRGUB7lkXX",
        "outputId": "0179cffc-0fc0-4055-f68d-f2caf6c58e41"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF rows available for evaluation: 215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 7: Evaluate OOF Predictions\n",
        "# ==============================================================================\n",
        "\n",
        "from sklearn.metrics import brier_score_loss\n",
        "\n",
        "def compute_brier_censored(event, time_to_hit, y_pred, horizon):\n",
        "    include = ((event == 1) & (time_to_hit <= horizon)) | (time_to_hit > horizon)\n",
        "    label   = ((event == 1) & (time_to_hit <= horizon)).astype(int)\n",
        "    if include.sum() == 0:\n",
        "        return np.nan\n",
        "    return brier_score_loss(label[include], y_pred[include])\n",
        "\n",
        "oof_eval = oof_preds_eval.merge(\n",
        "    train[['event_id', 'event', 'time_to_hit_hours']], on='event_id', how='left'\n",
        ")\n",
        "\n",
        "briers = {}\n",
        "for H in [24, 48, 72]:\n",
        "    col   = f'prob_{H}h'\n",
        "    valid = oof_eval[col].notna()\n",
        "    bs = compute_brier_censored(\n",
        "        oof_eval.loc[valid, 'event'].values,\n",
        "        oof_eval.loc[valid, 'time_to_hit_hours'].values,\n",
        "        oof_eval.loc[valid, col].values,\n",
        "        H\n",
        "    )\n",
        "    briers[H] = bs\n",
        "    print(f\"OOF Brier@{H}h: {bs:.4f}\")\n",
        "\n",
        "weighted_brier = 0.3 * briers[24] + 0.4 * briers[48] + 0.3 * briers[72]\n",
        "print(f\"\\nWeighted Brier Score: {weighted_brier:.4f}\")\n",
        "print(f\"(1 - Weighted Brier): {1 - weighted_brier:.4f}\")\n",
        "\n",
        "try:\n",
        "    from lifelines.utils import concordance_index\n",
        "    c_idx  = concordance_index(\n",
        "        oof_eval['time_to_hit_hours'],\n",
        "        -oof_eval['prob_72h'],\n",
        "        oof_eval['event']\n",
        "    )\n",
        "    hybrid = 0.3 * c_idx + 0.7 * (1 - weighted_brier)\n",
        "    print(f\"C-index (OOF):          {c_idx:.4f}\")\n",
        "    print(f\"Estimated Hybrid Score: {hybrid:.4f}\")\n",
        "except ImportError:\n",
        "    print(\"Install lifelines for C-index: !pip install lifelines\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poHClGZGlkaE",
        "outputId": "4fdaee4c-9c1e-412c-8e22-b92d421eb1fe"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OOF Brier@24h: 0.0244\n",
            "OOF Brier@48h: 0.0175\n",
            "OOF Brier@72h: 0.0052\n",
            "\n",
            "Weighted Brier Score: 0.0159\n",
            "(1 - Weighted Brier): 0.9841\n",
            "Install lifelines for C-index: !pip install lifelines\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 8: SHAP Feature Importance\n",
        "# ==============================================================================\n",
        "\n",
        "print(\"\\nComputing SHAP values for 48h horizon model...\")\n",
        "mask_48        = horizon_masks['mask_48h']\n",
        "final_model_48 = lgb.LGBMClassifier(**BEST_PARAMS)\n",
        "final_model_48.fit(train.loc[mask_48, FEATURE_COLS], train.loc[mask_48, 'hit_48h'])\n",
        "\n",
        "explainer = shap.TreeExplainer(final_model_48)\n",
        "shap_vals = explainer.shap_values(train.loc[mask_48, FEATURE_COLS])\n",
        "\n",
        "if isinstance(shap_vals, list):\n",
        "    shap_vals = shap_vals[1]\n",
        "\n",
        "shap_importance = pd.DataFrame({\n",
        "    'feature':   FEATURE_COLS,\n",
        "    'mean_shap': np.abs(shap_vals).mean(axis=0)\n",
        "}).sort_values('mean_shap', ascending=False)\n",
        "\n",
        "print(\"\\nTop 15 most important features (by mean |SHAP|):\")\n",
        "print(shap_importance.head(15).to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZEi2wg1lkfR",
        "outputId": "822884c6-4968-433d-cca4-3647718289fb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Computing SHAP values for 48h horizon model...\n",
            "\n",
            "Top 15 most important features (by mean |SHAP|):\n",
            "                     feature  mean_shap\n",
            "            dist_min_ci_0_5h   6.205617\n",
            "                log_dist_min   3.080733\n",
            "            event_start_hour   0.826264\n",
            "         num_perimeters_0_5h   0.654496\n",
            "            is_close_to_evac   0.510823\n",
            "               area_first_ha   0.469008\n",
            "               alignment_abs   0.367906\n",
            "           event_start_month   0.272524\n",
            "            log1p_area_first   0.189738\n",
            "          dist_slope_ci_0_5h   0.143965\n",
            "       event_start_dayofweek   0.143117\n",
            "          dt_first_last_0_5h   0.142685\n",
            "            area_x_alignment   0.055772\n",
            "                is_peak_hour   0.052506\n",
            "low_temporal_resolution_0_5h   0.031037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 9: Calibration Pass (Platt Scaling)\n",
        "# ==============================================================================\n",
        "# Fits a logistic regression on OOF predictions vs true labels, then applies\n",
        "# that correction to test predictions. Directly reduces Brier score.\n",
        "\n",
        "calibrated_test_preds = test_preds.copy()\n",
        "\n",
        "for H in HORIZONS:\n",
        "    col = f'prob_{H}h'\n",
        "\n",
        "    oof_h  = oof_preds[['event_id', col]].dropna(subset=[col])\n",
        "    cal_df = oof_h.merge(\n",
        "        train[['event_id', f'hit_{H}h']], on='event_id', how='inner'\n",
        "    )\n",
        "\n",
        "    if len(cal_df) < 10:\n",
        "        print(f\"  {H}h: not enough OOF samples to calibrate, skipping\")\n",
        "        continue\n",
        "\n",
        "    oof_sub = cal_df[col].values\n",
        "    y_sub   = cal_df[f'hit_{H}h'].values\n",
        "\n",
        "    if len(np.unique(y_sub)) < 2:\n",
        "        # 72h is 100% hits -- no negative class to fit against.\n",
        "        # Cap slightly below 1.0 to avoid max Brier penalty on any wrong prediction.\n",
        "        print(f\"  {H}h: only one class in OOF labels -- capping test preds at 0.97\")\n",
        "        calibrated_test_preds[col] = calibrated_test_preds[col].clip(upper=0.97)\n",
        "        continue\n",
        "\n",
        "    platt = LogisticRegression(C=1.0, solver='lbfgs')\n",
        "    platt.fit(oof_sub.reshape(-1, 1), y_sub)\n",
        "    calibrated_test_preds[col] = platt.predict_proba(\n",
        "        test_preds[col].values.reshape(-1, 1)\n",
        "    )[:, 1]\n",
        "    print(f\"  Calibrated {H}h: test mean prob {calibrated_test_preds[col].mean():.3f}\")\n",
        "\n",
        "calibrated_test_preds = enforce_monotonicity(calibrated_test_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFZzp7p5lkms",
        "outputId": "c09a770f-c5df-4188-940f-63d28f8ef1c1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Calibrated 12h: test mean prob 0.178\n",
            "  Calibrated 24h: test mean prob 0.273\n",
            "  Calibrated 48h: test mean prob 0.292\n",
            "  72h: only one class in OOF labels -- capping test preds at 0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# STEP 10: Build and Validate Submission\n",
        "# ==============================================================================\n",
        "\n",
        "submission     = calibrated_test_preds[['event_id', 'prob_12h', 'prob_24h', 'prob_48h', 'prob_72h']].copy()\n",
        "prob_col_names = ['prob_12h', 'prob_24h', 'prob_48h', 'prob_72h']\n",
        "\n",
        "assert submission['event_id'].nunique() == len(submission), \\\n",
        "    \"Duplicate IDs found!\"\n",
        "assert set(submission['event_id']) == set(sub['event_id']), \\\n",
        "    \"ID mismatch with sample submission!\"\n",
        "\n",
        "# DataFrame does not have .between() -- apply it column-wise instead\n",
        "in_range = submission[prob_col_names].apply(lambda col: col.between(0, 1)).all().all()\n",
        "assert in_range, \"Probabilities out of [0, 1]!\"\n",
        "\n",
        "violations = (\n",
        "    (submission['prob_12h'] > submission['prob_24h']) |\n",
        "    (submission['prob_24h'] > submission['prob_48h']) |\n",
        "    (submission['prob_48h'] > submission['prob_72h'])\n",
        ")\n",
        "assert not violations.any(), f\"Monotonicity violated in {violations.sum()} rows!\"\n",
        "\n",
        "print(\"\\nAll submission checks passed!\")\n",
        "print(submission[prob_col_names].describe().round(3))\n",
        "\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print(\"\\nSaved: submission.csv\")\n",
        "\n",
        "# ==============================================================================\n",
        "# BONUS: What to try if score is not high enough\n",
        "# ==============================================================================\n",
        "# 1. Increase Optuna trials (n_trials=100+)\n",
        "# 2. Blend with RandomSurvivalForest from scikit-survival for better C-index ranking\n",
        "# 3. Stack: train a meta-model on OOF probs from multiple base model types\n",
        "# 4. Try isotonic regression calibration as an alternative to Platt scaling\n",
        "# 5. Engineer fire-behavior features: wind alignment, terrain slope if available"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT85RX6Hlkp7",
        "outputId": "964011a3-93d3-40b0-9820-38939db10446"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "All submission checks passed!\n",
            "       prob_12h  prob_24h  prob_48h  prob_72h\n",
            "count    95.000    95.000    95.000    95.000\n",
            "mean      0.178     0.274     0.292     0.314\n",
            "std       0.226     0.353     0.370     0.403\n",
            "min       0.052     0.052     0.055     0.055\n",
            "25%       0.052     0.052     0.056     0.056\n",
            "50%       0.053     0.053     0.057     0.057\n",
            "75%       0.244     0.770     0.872     0.941\n",
            "max       0.815     0.882     0.898     0.970\n",
            "\n",
            "Saved: submission.csv\n"
          ]
        }
      ]
    }
  ]
}